- 本人確認業務をオンラインで行うサービス
    - eKYC
- アラート運用を改善

# アラートに対してちゃんと向き合う

- Rails
- モノリス
- Sentryで500エラーを見て対応
- 利用状況が大きくなってエッヂケースが増えてきた
- アラートの取りこぼしが発生していた
- 可用性ではなく、個別事象の対応に課題
- お客様影響のあるアラートが上がってくる状況が理想
- 単純なエラー率のSLISLOを設定しても個別事象の取りこぼしの課題間はなくならなさそう
- 二重送信の問題の対処での発生
- このフローが問題なく進むこと自体が信頼性に直結する、CUJだ！！
    - どっか欠けるとダメ

# ケース

- 全部落ちてる
    - 影響でかい
- どれかが常に落ちてる
    - 影響でかい
- 1-4のうち数件が進まない
    - 影響中
- 回避策はあるが1-4のうち数件が進まない
    - 影響小
- 全部は大体気づけるよね
- どれかが常に、はSentryとかのEscalatingで気づける
- 中、小は気づきづらい
    - トリアージに課題感

# トリアージ体制の構築

- 中、小のトリアージに焦点をあてる
- 機械的な判断は諦めた
    - 個別のエラーが想定できるならそもそもエラーは発生してない
- アラートを見て影響度を決める
    - ヒューマンオペレーション
    - 一定のご判断は諦める
- トリアージ、暫定対応までの時間はある
    - トリアージまでの時間設定がSLI
- 影響度が小のものはアラートしない


- アラートを各チームでそれぞれ確認する
    - 曜日ごと、など
    - 人数がいないと対応できない
    - 3人以上いないとダメ
    - トイルの性質が強い
    - 人員配置で工夫せよ
- 通知のあったSentryのアラートを都度確認して判断
    - ドメインの知識、スキルを求められる
    - チームでカバーしていく
    - #dev-アラート疑惑相談
        - 心理的ハードルを下げる
    - ドキュメント整備
- 影響度が小の場合はSentry上でアーカイブ、次回は通知せず

# 長期的に改善したほうがよいものの対処

- devOpsは前提
- E2Eとか
- Sentryのアーカイブは定期的に点検する
    - 週一
- コードを修正しないとアラートの種類は変わらない
    - 可用性は向上しない
- エラー率、エラー詳細、応答時間を確認
    - 対応のコスパが良さそうなものを優先的に対処
- 時間のかかっている定期ジョブを先に把握しておく、このまま伸びると障害になる、など
- 先週なかったエラーが増えてる、など
- 改善活動へのリソース
    - エラーバジェットは設定しきれていない
    - かなりむずい
    - 影響度が大きいやつは最優先で合意
    - 小さいやつは実装者へエスカレーションを行って修正してもらう
        - アラート改善活動のリソースを確保するように話をつけている
- インフラに限らず改善している
    - リトライ最適化、パフォーマンス改善など

# まとめ

- 中、小の運用不可について考えているよー
- 時間を確保しているよー